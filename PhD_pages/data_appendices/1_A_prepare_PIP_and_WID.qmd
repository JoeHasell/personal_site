---
title: "Appendix 1.A: Preparing PIP and WID inequality data"
format: html
warning: false

---

# Processing steps

The titles in each of the boxes below summarise the steps taken to prepare the PIP and WID data. In each case you can expand the box to see the code used.

::: {.callout-note collapse="true" appearance="minimal"}
### Load packages

```{r}
library(tidyverse)
library(knitr)

```

```{python}
# For some reason I can't get the owid package working when rendering... only when running in the interactive window in vs code
# from owid import catalog
import pandas as pd
```
:::

## PIP data

::: {.callout-note collapse="true" appearance="minimal"}
### Load PIP data
We load the data from a file prepared from the PIP API by Our World in Data.
```{r}
# df_pip<- read.csv("https://raw.githubusercontent.com/owid/poverty-data/main/datasets/pip_dataset.csv")

#  A local version, in case internet isn't available 
df_pip<- read.csv("data/original/pip_dataset.csv")

```

The dataframe looks like this:
```{r}
kable(

    head(df_pip, 50)
    
)
```
:::


::: {.callout-note collapse="true" appearance="minimal"}
### Drop sub-national data

The PIP data includes observations for national, urban and rural populations (`reporting_level`):

```{r}
kable(
    df_pip %>%
        count(reporting_level)
)
```

Here we add a count of the number of reporting levels per country-year.
```{r}

count_reporting_levels<- df_pip %>%
    group_by(country, year) %>%
    count(reporting_level) %>%
    group_by(country, year) %>%
    summarise(n_reporting_levels = n())

df_pip<- left_join(df_pip, count_reporting_levels) %>%
    relocate(n_reporting_levels, .after=reporting_level)



kable(

    head(df_pip, 20)

)
```

We only want one reporting level for each country-year.

That is already true for most country-years. But some include all three reporting levels.
```{r}
kable(

    df_pip %>%
        count(n_reporting_levels)

)

```

Here are the countries which include all three reporting levels:
```{r}
multi_reporting_level_countries<- 
    df_pip %>%
        filter(n_reporting_levels == 3) %>%
        select(country) %>%
        unique() %>%
        pull(country)

print(multi_reporting_level_countries)

```

For the country-years with 3 reporting levels, we keep only the national estimates. 
```{r}
df_pip<- df_pip %>%
    filter(n_reporting_levels != 3 | reporting_level == 'national' )


```
:::


::: {.callout-note collapse="true" appearance="minimal"}
### Drop regional data

The dataset includes aggregated estiates for world regions.

Here we define a list of these aggregate entities and drop them from the data.
```{r}
drop_aggs<- c(
  "East Asia and Pacific",
  "South Asia",
  "Europe and Central Asia",
  "High income countries",
  "Latin America and the Caribbean",
  "Middle East and North Africa",
  "Sub-Saharan Africa",
  "World"
)

df_pip<- df_pip %>%
  filter(!country %in% drop_aggs)

```
:::



::: {.callout-note collapse="true" appearance="minimal"}
### Select 2017 PPPs

The data is provided by the World Bank in both 2011 and 2017 PPPs.

We will be using 2017 PPPs for Paper 1.

```{r}

df_pip<- df_pip %>%
  filter(ppp_version == 2017)

```
:::




::: {.callout-note collapse="true" appearance="minimal"}
### Drop extremely low P10 values


There are some very low values of P10. These lead to exaggerated values of the P90/P10 ratio.

```{r}


kable(
    df_pip %>% filter(decile1_thr<0.02)

  )

```

We set these values of P10 to NA, and thereby precluding a value for P90/P10 ratio when it is calculated below.

```{r}

df_pip<- df_pip %>%
  mutate(decile1_thr = if_else(decile1_thr<0.02,
                              as.numeric(NA),
                              decile1_thr))


kable(
    df_pip %>% filter(is.na(decile1_thr))

  )


```

:::


::: {.callout-note collapse="true" appearance="minimal"}
### Calculate additional variables


```{r}

df_pip<- df_pip %>%
  mutate(Bottom_50_share = decile1_share + decile2_share + decile3_share + decile4_share + decile5_share,
          P90_P10_ratio = decile9_thr/decile1_thr,
          gini = gini * 100)


```
:::

::: {.callout-note collapse="true" appearance="minimal"}
### Rename and select needed columns
```{r}

df_pip<- df_pip %>%
  rename("Gini" = "gini",
         "Top_10_share" = "decile10_share",
         "MLD" = "mld",
         "Entity" = "country",
         "Year" = "year")


df_pip<- df_pip %>%
    select(
        Year,
        Entity,
        Gini,
        Top_10_share,
        Bottom_50_share,
        MLD,
        P90_P10_ratio,
        welfare_type)



```
:::



::: {.callout-note collapse="true" appearance="minimal"}
### See the prepared PIP data

The first 100 rows of the dataframe looks like this:
```{r}
kable(

    head(df_pip, 100)
    
)
```

:::

::: {.callout-note collapse="true" appearance="minimal"}
### Save the data
I save the prepared data locally:
```{r}

write.csv(df_pip, 
      "data/clean/pip.csv", row.names=FALSE)

```
:::


## WID data

::: {.callout-note collapse="true" appearance="minimal"}
### Load WID data
We load the data from a file prepared from the WID Stata package by Our World in Data.

```{r}
# df_wid<- read.csv("https://raw.githubusercontent.com/owid/notebooks/main/BetterDataDocs/PabloArriagada/WID/data/final/wid_pretax.csv")

# A local version, in case internet isn't available 
df_wid<- read.csv("data/original/wid.csv")

```

The dataframe looks like this:
```{r}
kable(

    head(df_wid, 50)
    
)
```
:::



::: {.callout-note collapse="true" appearance="minimal"}
### Drop subnational, regional and historical geographical entities

Here we create a list of entities in the WID data that do not correspond to countries in existence today. These we drop from the data.
```{r}
drop_entities<- c(
"China - rural",
"China - urban",
"East Germany",
"Other Russia and Central Asia",
"Other East Asia",
"Other Western Europe",
"Other Latin America",
"Other MENA",
"Other South & South-East Asia",
"Other Sub-Saharan Africa",
"Africa",
"Asia",
"Europe",
"Oceania",
"Central Asia",
"East Africa",
"East Asia",
"South Asia",
"Eastern Europe",
"Middle Africa",
"North Africa",
"North America",
"South-East Asia",
"South Africa region",
"West Africa",
"West Asia",
"Western Europe",
"European Union",
"World",
"Asia (excluding Middle East)",
"North America and Oceania",
"Sub-Saharan Africa",
"Latin America",
"Middle East",
"MENA",
"Russia and Central Asia",
"South & South-East Asia"
)

df_wid<- df_wid %>%
  filter(!Entity %in% drop_entities)
```
:::



::: {.callout-note collapse="true" appearance="minimal"}
### Drop extremely low P10 values


There are some very low values of P10. These lead to exaggerated values of the P90/P10 ratio. Here are all values less than $1 a day (using pretax national income)

```{r}


kable(
    df_wid %>% filter(P10...income.threshold/365<1)

  )

```

We set these values of P10 to NA, and thereby precluding a value for P90/P10 ratio when it is calculated below.

```{r}

df_wid<- df_wid %>%
  mutate(P10...income.threshold = if_else(P10...income.threshold/365<1,
                              as.numeric(NA),
                              P10...income.threshold))

                              kable(
    df_wid %>% filter(is.na(P10...income.threshold))

  )

```

:::

::: {.callout-note collapse="true" appearance="minimal"}
### Calculate some additional inequality metrics


```{r}

#  Calculate P90_P10_ratio
df_wid<- df_wid %>%
    mutate(P90_P10_ratio = `P90...income.threshold.of.the.top.10.`/P10...income.threshold,
    Gini = Gini.coefficient * 100)

```
:::


::: {.callout-note collapse="true" appearance="minimal"}
### Rename and select needed variables


```{r}
df_wid<- df_wid %>%
    rename("Top_10_share" = "P90.P100...share.of.the.top.10.",
         "Bottom_50_share"= "P0.P50...share.of.the.bottom.50.",
         "P90" = "P90...income.threshold.of.the.top.10.",
         "P10" = "P10...income.threshold") %>%
    select(
        Year,
        Entity,
        Gini,
        Top_10_share,
        # MLD,
        P90_P10_ratio,
        Bottom_50_share,
        P90,
        P10)

```
:::


::: {.callout-note collapse="true" appearance="minimal"}
### See the prepared WID data

The first 100 rows of the dataframe looks like this:
```{r}
kable(

    head(df_wid, 100)
    
)
```

::: {.callout-note collapse="true" appearance="minimal"}
### Save the data
I save the prepared data locally:
```{r}

write.csv(df_wid, 
      "data/clean/wid.csv", row.names=FALSE)


```
:::
:::


## LIS data

::: {.callout-note collapse="true" appearance="minimal"}
### Load WID data
We load the data from a file prepared from the WID Stata package by Our World in Data.

```{r}

from owid import catalog



# results = catalog.find('population')
# owid_pop = results[results['path'] == 'garden/owid/latest/key_indicators/population']

# df_pop = owid_pop.iloc[0].load().reset_index().rename(columns={'year':'Year', 'country': 'Entity'})

# df_pop.head()

# df_wid<- read.csv("https://raw.githubusercontent.com/owid/notebooks/main/BetterDataDocs/PabloArriagada/WID/data/final/wid_pretax.csv")

# A local version, in case internet isn't available 
# df_wid<- read.csv("data/original/wid.csv")

```




## Additional variables
::: {.callout-note collapse="true" appearance="minimal"}
### Region classfications
For regional classifications I take WID definitions, as specified on their website [here](https://wid.world/codes-dictionary/#country-code).

I read in a csv prepared from the table in that webpage, which has been mapped to the Our World in Data standarized country names used throughout this project.
```{r}

# df_regions<- read.csv("data/original/WID_regions_country_standardized.csv")

```

```{python}

df_regions = pd.read_csv("data/original/WID_regions_country_standardized.csv")

```

I create a clean region mapping table using two regional definitions. One is the 'standard' definitions used by WID. In an alternative set I split Western and Eastern Europe, ccombining the latter with Russia & Central Asia to make a joint Eastern Europe and Central Asia region. 
```{r}

# df_regions<- df_regions %>%
#   select(Our.World.In.Data.Name, `region..standard.`, sub.region) %>%
#   rename(Entity = Our.World.In.Data.Name,
#         WID_region = `region..standard.`) %>%
#   mutate(region_alt = if_else(sub.region == 'Western Europe',
#   'Western Europe',
#   WID_region)) %>%
#   mutate(region_alt = if_else((sub.region == 'Eastern Europe' | WID_region == "Russia & Central Asia"),
#   'Eastern Europe & Central Asia',
#   WID_region)) %>%
#   select(Entity, WID_region, region_alt)


# kable(
#   df_regions
# )
```

```{python}

df_regions = df_regions[['Our World In Data Name', 'region (standard)', 'sub-region']].rename(columns={'Our World In Data Name': 'Entity', 'region (standard)': 'WID_region'})

# Define an alt region classification
df_regions['region_alt'] = df_regions['WID_region']

df_regions.loc[df_regions['sub-region'] == 'Western Europe','region_alt'] = 'Western Europe'

df_regions.loc[(df_regions['sub-region'] == 'Eastern Europe') | (df_regions['WID_region'] == 'Russia & Central Asia'),'region_alt'] = 'Eastern Europe & Central Asia'


```

Check that no countries are not matched for either dataset.
```{r}
# # Merge in the regions dataset
# df_pip<- left_join(df_pip, df_regions)
# df_wid<- left_join(df_wid, df_regions)


# # PIP check
# kable(
#   df_pip %>% 
#     select(Entity, WID_region, region_alt) %>%
#     unique() %>%
#     filter(is.na(WID_region))
# )

# # WID check
# kable(
#   df_wid %>% 
#     select(Entity, WID_region, region_alt) %>%
#     unique() %>%
#     filter(is.na(WID_region))
# )

```

Save the region mapping
```{r}
# write.csv(df_regions, 
#       "data/clean/WID_region_mapping.csv", row.names=FALSE)

```

```{python}

df_regions.to_csv('data/clean/WID_region_mapping.csv')

```
:::


::: {.callout-note collapse="true" appearance="minimal"}
### Population

```{python}
# For some reason I can't get the owid package working when rendering... only when running in the interactive window in vs code
# results = catalog.find('population')
# owid_pop = results[results['path'] == 'garden/owid/latest/key_indicators/population']

# df_pop = owid_pop.iloc[0].load().reset_index().rename(columns={'year':'Year', 'country': 'Entity'})

# df_pop.head()

```


Check we have population for each country
```{python}
# df_pop = pd.read_csv('data/clean/population.csv')

# df_wid = pd.read_csv("data/clean/wid.csv")
# df_pip = pd.read_csv("data/clean/pip.csv")

# check_pip = pd.merge(df_pip, df_pop, how = 'left')
# check_pip[check_pip['population'].isna()]

# check_wid = pd.merge(df_wid, df_pop, how = 'left')
# check_wid[check_wid['population'].isna()]

# # There's no population for Zanzibar in the OWID data
# # For now I make up a population series based on two data points from Wikipedia. At some point I can come back and replaces this with the WID population data

# zanz_pop_1978 = 476111
# zanz_pop_2022 = 1889773

# # Assume a constant growth rate
# zanz_g = pow(zanz_pop_2022/zanz_pop_1978, 1/(2022-1978))-1

# year = 2022
# pop = zanz_pop_1978 * pow(1+zanz_g, year - 1978)

# df_zanz_pop = df_wid[df_wid['Entity'] == "Zanzibar"].copy()
# df_zanz_pop['population'] = zanz_pop_1978 * pow(1+zanz_g, df_zanz_pop['Year'] - 1978)

# df_zanz_pop = df_zanz_pop[['Entity', 'Year', 'population']]

# df_pop = pd.concat([df_pop, df_zanz_pop])

```

Save the population data
```{python}
# df_pop.to_csv('data/clean/population.csv')

```

:::





## Important notes

### Income and consumption data in PIP
The PIP data includes a mix of income and consumption observations – including both for some country-years.


### Coverage


::: {.callout-note collapse="true" appearance="minimal"}
### Compare countries available across datasets
```{r}

pip_countries<- df_pip %>%
  select(Entity) %>%
  unique() %>%
  mutate(Entity_pip = Entity)

wid_countries<- df_wid %>%
  select(Entity) %>%
  unique() %>%
  mutate(Entity_wid = Entity)

countries<- full_join(pip_countries, wid_countries, keep = TRUE) %>%
  select(Entity_pip, Entity_wid)

```

Countries that are in the PIP data but not the WID data:
```{r}
kable(
  countries %>%
       filter(is.na(Entity_wid))
)
```
Countries that are in the WID data but not the PIP data:
```{r}
kable(
  countries %>%
       filter(is.na(Entity_pip))
)
```
:::

### Outliers
::: {.callout-note collapse="true" appearance="minimal"}
### P90/P10 ratio

For the P90/P10 ratio, a few observations have extreme values. In the PIP data
```{r}
kable(

  df_pip %>% arrange(-P90_P10_ratio) %>% head()
)

```

And the WID data:

```{r}
kable(

  df_wid %>% arrange(-P90_P10_ratio) %>% head(100)
)

```

:::
